{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure python 3 compatibility\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# Import necessary libraries:\n",
    "# General utilities:\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Computation:\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Visualization:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Finally, pycroscopy itself\n",
    "import pycroscopy as px\n",
    "\n",
    "from os.path import join as pjoin\n",
    "\n",
    "# set up notebook to show plots within the notebook\n",
    "% matplotlib inline\n",
    "\n",
    "import glob\n",
    "\n",
    "#import moviepy.video.io.ImageSequenceClip\n",
    "#try:\n",
    "#    output = subprocess.check_output(['ffmpeg', '-version'])\n",
    "#    version = output.split(b'\\n')[0].split()[2]\n",
    "#    print('Found: ffmpeg v{}'.format(version.decode('utf-8')))\n",
    "#    ffmpeg_installed = True\n",
    "#except:\n",
    " #   ffmpeg_installed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting custom.mplstyle\n"
     ]
    }
   ],
   "source": [
    "%%file custom.mplstyle\n",
    "\n",
    "axes.linewidth: 1.5\n",
    "xtick.major.size: 6\n",
    "xtick.minor.size: 2\n",
    "xtick.major.width: 1.5\n",
    "xtick.minor.width: 1.5\n",
    "ytick.major.size: 6\n",
    "ytick.minor.size: 2\n",
    "ytick.major.width: 1.5\n",
    "ytick.minor.width: 1.5\n",
    "axes.labelweight: bold\n",
    "axes.labelpad: 1\n",
    "axes.labelsize: 12\n",
    "xtick.major.pad: 1\n",
    "ytick.major.pad: 1\n",
    "xtick.labelsize: 12\n",
    "ytick.labelsize: 12\n",
    "xtick.top: True\n",
    "ytick.right: True\n",
    "xtick.direction: in\n",
    "ytick.direction: in\n",
    "image.interpolation: nearest\n",
    "    \n",
    "# Loads the custom style\n",
    "plt.style.use('./custom.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Josh_\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:955: UserWarning: Illegal line #25\n",
      "\t\"plt.style.use('./custom.mplstyle')\"\n",
      "\tin file \"./custom.mplstyle\"\n",
      "  warnings.warn('Illegal %s' % error_details)\n"
     ]
    }
   ],
   "source": [
    "plt.style.use('./custom.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File is already Pycroscopy ready.\n",
      "Working on:\n",
      "D:/Scan_8_ckpfm/Doped_PZT_001_ckpfm_0015.h5\n"
     ]
    }
   ],
   "source": [
    " input_file_path ='D:/Scan_8_ckpfm/Doped_PZT_001_ckpfm_0015.h5' #px.io_utils.uiGetFile(caption='Select translated .h5 file or raw experiment data',\n",
    "                                         #filter='Translated file (*.h5);; \\\\ Parameters for raw BE data (*.txt *.mat *xls *.xlsx)')\n",
    "\n",
    "(data_dir, data_name) = os.path.split(input_file_path)\n",
    "\n",
    "if input_file_path.endswith('.h5'):\n",
    "    # No translation here\n",
    "    h5_path = input_file_path\n",
    "    tl = px.LabViewH5Patcher()\n",
    "    hdf = tl.translate(h5_path)\n",
    "else:\n",
    "    # Set the data to be translated\n",
    "    data_path = input_file_path\n",
    "\n",
    "    (junk, base_name) = os.path.split(data_dir)\n",
    "\n",
    "    # Check if the data is in the new or old format.  Initialize the correct translator for the format.\n",
    "    if base_name == 'newdataformat':\n",
    "        (junk, base_name) = os.path.split(junk)\n",
    "        translator = px.BEPSndfTranslator(max_mem_mb=max_mem)\n",
    "    else:\n",
    "        translator = px.BEodfTranslator(max_mem_mb=max_mem)\n",
    "    if base_name.endswith('_d'):\n",
    "        base_name = base_name[:-2]\n",
    "    # Translate the data\n",
    "    h5_path = translator.translate(data_path, show_plots=True, save_plots=False)\n",
    "    tl = px.LabViewH5Patcher()\n",
    "    hdf = tl.translate(h5_path)\n",
    "print('Working on:\\n' + h5_path)\n",
    "\n",
    "h5_main = px.hdf_utils.getDataSet(hdf.file, 'Raw_Data')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taking previous SHO results already present in file\n"
     ]
    }
   ],
   "source": [
    "h5_sho_group = px.hdf_utils.findH5group(h5_main, 'SHO_Fit')\n",
    "sho_fitter = px.BESHOmodel(h5_main, parallel=True)\n",
    "if len(h5_sho_group) == 0:\n",
    "    print('No SHO fit found. Doing SHO Fitting now')\n",
    "    h5_sho_guess = sho_fitter.do_guess(strategy='complex_gaussian', processors=max_cores)\n",
    "    h5_sho_fit = sho_fitter.do_fit(processors=max_cores)\n",
    "else:\n",
    "    print('Taking previous SHO results already present in file')\n",
    "    h5_sho_guess = h5_sho_group[-1]['Guess']\n",
    "    try:\n",
    "        h5_sho_fit = h5_sho_group[-1]['Fit']\n",
    "    except KeyError:\n",
    "        print('Previously computed guess found. Now computing fit')\n",
    "        h5_sho_fit = sho_fitter.do_fit(processors=max_cores, h5_guess=h5_sho_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify output file path\n",
    "output_file_path = './'\n",
    "\n",
    "# If HV amplifier was used set high_voltage_amplf to 10, else to 1\n",
    "high_voltage_amplf = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshape Success = True\n",
      "Nd_mat shape =  (70, 70, 2, 84, 11)\n",
      "Phase offset [rad] =  0.199172\n"
     ]
    }
   ],
   "source": [
    "(Nd_mat, success) = px.io.hdf_utils.reshape_to_Ndims(h5_sho_fit)\n",
    "print('Reshape Success = ' + str(success))\n",
    "print('Nd_mat shape = ', Nd_mat.shape)\n",
    "\n",
    "phase_offset = Nd_mat[0, 0, 1, 0, 0]['Phase [rad]']\n",
    "\n",
    "# phase_offset = 0;\n",
    "\n",
    "print('Phase offset [rad] = ', phase_offset)\n",
    "\n",
    "Nd_mat[:,:,:,:,:]['Phase [rad]'] = Nd_mat[:,:,:,:,:]['Phase [rad]'] - phase_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([( 0.00311499,  325349.59375,  305.64855957,  0.16913097,  0.90679371)],\n",
       "      dtype=[('Amplitude [V]', '<f4'), ('Frequency [Hz]', '<f4'), ('Quality Factor', '<f4'), ('Phase [rad]', '<f4'), ('R2 Criterion', '<f4')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Nd_mat[:1,1,1,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import pycroscopy as px\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as pjoin\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import (Dense, Conv1D, Convolution2D, GRU, LSTM, Recurrent, Bidirectional, TimeDistributed,\n",
    "                          Dropout, Flatten, RepeatVector, Reshape, MaxPooling1D, UpSampling1D, BatchNormalization)\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from keras.regularizers import l1\n",
    "import sys\n",
    "\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(qf_on.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(qf_on.reshape(-1))):\n",
    "    if qf_on.reshape(-1)[i] > 900:\n",
    "        qf_on.reshape(-1)[i] = np.mean(qf_on)\n",
    "        \n",
    "for i in range(len(qf_off.reshape(-1))):\n",
    "    if qf_off.reshape(-1)[i] > 900:\n",
    "        qf_off.reshape(-1)[i] = np.mean(qf_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(indat):\n",
    "    indat-=np.mean(indat)\n",
    "    indat/=np.std(indat)\n",
    "    return indat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.hist(qf_on.reshape(-1),100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.std((Nd_mat[\"Amplitude [V]\"][:,:,:,1,2].reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amp_off = np.atleast_3d(Nd_mat[\"Amplitude [V]\"][:,:,:,1,2].reshape(-1,128))\n",
    "phase_off = np.atleast_3d(Nd_mat[\"Phase [rad]\"][:,:,:,1,2].reshape(-1,128))\n",
    "freq_off = np.atleast_3d(Nd_mat[\"Frequency [Hz]\"][:,:,:,1,2].reshape(-1,128))\n",
    "qf_off = np.atleast_3d(Nd_mat[\"Quality Factor\"][:,:,:,1,2].reshape(-1,128))\n",
    "\n",
    "amp_on = np.atleast_3d(Nd_mat[\"Amplitude [V]\"][:,:,:,0,2].reshape(-1,128))\n",
    "phase_on = np.atleast_3d(Nd_mat[\"Phase [rad]\"][:,:,:,0,2].reshape(-1,128))\n",
    "freq_on = np.atleast_3d(Nd_mat[\"Frequency [Hz]\"][:,:,:,0,2].reshape(-1,128))\n",
    "qf_on= np.atleast_3d(Nd_mat[\"Quality Factor\"][:,:,:,0,2].reshape(-1,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amp_off = np.atleast_3d(norm(amp_off))\n",
    "phase_off = np.atleast_3d(norm(phase_off))\n",
    "freq_off = np.atleast_3d(norm(freq_off))\n",
    "qf_off = np.atleast_3d(norm(qf_off))\n",
    "\n",
    "amp_on = np.atleast_3d(norm(amp_on))\n",
    "phase_on = np.atleast_3d(norm(phase_on))\n",
    "freq_on = np.atleast_3d(norm(freq_on))\n",
    "qf_on= np.atleast_3d(norm(qf_on))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_folder(folder_name, root='./'):\n",
    "\n",
    "    folder = pjoin(root, '{}'.format(folder_name))\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    return (folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_layer(size, numbernodes,x):\n",
    "    for i in range(size-1):\n",
    "        x = Bidirectional(LSTM(numbernodes, return_sequences=True))(x)\n",
    "    out = Bidirectional(LSTM(numbernodes, return_sequences=False))(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_layer(size, numbernodes,x):\n",
    "    x = RepeatVector(128)(x)\n",
    "    for i in range(size):\n",
    "        x = Bidirectional(LSTM(numbernodes, return_sequences=True))(x)\n",
    "    x = TimeDistributed(Dense(1, activation='linear'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_on_amp = Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2],1))\n",
    "input_off_amp =Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2],1))\n",
    "input_on_phase =Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2],1))\n",
    "input_off_phase =Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2],1))\n",
    "input_on_resonance =Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2],1))\n",
    "input_off_resonance = Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2],1))\n",
    "input_on_loss =Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2],1))\n",
    "input_off_loss =Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2],1))\n",
    "\n",
    "\n",
    "en_out_a_on = encode_layer(3,16,input_on_amp)\n",
    "en_out_a_on = Dense(4, activation='relu',activity_regularizer=l1(10e-4))(en_out_a_on)\n",
    "en_out_a_off = encode_layer(3,16,input_off_amp)\n",
    "en_out_a_off = Dense(4, activation='relu',activity_regularizer=l1(10e-4))(en_out_a_off)\n",
    "en_out_p_on = encode_layer(3,16,input_on_phase)\n",
    "en_out_p_on = Dense(4, activation='relu',activity_regularizer=l1(10e-4))(en_out_p_on)\n",
    "en_out_p_off = encode_layer(3,16,input_off_phase)\n",
    "en_out_p_off = Dense(4, activation='relu',activity_regularizer=l1(10e-4))(en_out_p_off)\n",
    "en_out_r_on = encode_layer(3,16,input_on_resonance)\n",
    "en_out_r_on = Dense(4, activation='relu',activity_regularizer=l1(10e-4))(en_out_r_on)\n",
    "en_out_r_off = encode_layer(3,16,input_off_resonance)\n",
    "en_out_r_off = Dense(4, activation='relu',activity_regularizer=l1(10e-4))(en_out_r_off)\n",
    "en_out_l_on = encode_layer(3,16,input_on_loss)\n",
    "en_out_l_on = Dense(4, activation='relu',activity_regularizer=l1(10e-4))(en_out_l_on)\n",
    "en_out_l_off = encode_layer(3,16,input_off_loss)\n",
    "en_out_l_off = Dense(4, activation='relu',activity_regularizer=l1(10e-4))(en_out_l_off)\n",
    "\n",
    "\n",
    "\n",
    "x = keras.layers.concatenate([en_out_a_on, en_out_a_off, en_out_p_on, en_out_p_off,\n",
    "                              en_out_r_on, en_out_r_off, en_out_l_on, en_out_l_off])\n",
    "\n",
    "x = Dense(12, activation='relu',activity_regularizer=l1(10e-4))(x)\n",
    "\n",
    "de_out_a_on = decode_layer(3,16,x)\n",
    "de_out_a_off =decode_layer(3,16,x)\n",
    "de_out_p_on = decode_layer(3,16,x)\n",
    "de_out_p_off =decode_layer(3,16,x)\n",
    "de_out_r_on = decode_layer(3,16,x)\n",
    "de_out_r_off =decode_layer(3,16,x)\n",
    "de_out_l_on = decode_layer(3,16,x)\n",
    "de_out_l_off =decode_layer(3,16,x)\n",
    "\n",
    "model = Model(inputs=[input_on_amp, input_off_amp, input_on_phase, input_off_phase, input_on_resonance,\n",
    "                      input_off_resonance, input_on_loss, input_off_loss], \n",
    "              outputs=[de_out_a_on, de_out_a_off, de_out_p_on, de_out_p_off, de_out_r_on, de_out_r_off,\n",
    "                       de_out_l_on, de_out_l_off])\n",
    "\n",
    "model.compile(optimizer=Adam(3e-5),loss='mse')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6400 samples, validate on 6400 samples\n",
      "Train on 6400 samples, validate on 6400 samples\n",
      "Epoch 1/20000\n",
      "Epoch 1/20000\n",
      "6400/6400 [==============================] - 173s 27ms/step - loss: 9.0316 - time_distributed_1_loss: 0.9985 - time_distributed_2_loss: 1.0004 - time_distributed_3_loss: 0.9909 - time_distributed_4_loss: 1.0083 - time_distributed_5_loss: 0.9978 - time_distributed_6_loss: 1.0011 - time_distributed_7_loss: 1.0115 - time_distributed_8_loss: 1.0043 - val_loss: 8.9808 - val_time_distributed_1_loss: 0.9984 - val_time_distributed_2_loss: 1.0002 - val_time_distributed_3_loss: 0.9911 - val_time_distributed_4_loss: 1.0076 - val_time_distributed_5_loss: 0.9977 - val_time_distributed_6_loss: 1.0008 - val_time_distributed_7_loss: 1.0102 - val_time_distributed_8_loss: 1.0039\n",
      "6400/6400 [==============================] - 173s 27ms/step - loss: 9.0316 - time_distributed_1_loss: 0.9985 - time_distributed_2_loss: 1.0004 - time_distributed_3_loss: 0.9909 - time_distributed_4_loss: 1.0083 - time_distributed_5_loss: 0.9978 - time_distributed_6_loss: 1.0011 - time_distributed_7_loss: 1.0115 - time_distributed_8_loss: 1.0043 - val_loss: 8.9808 - val_time_distributed_1_loss: 0.9984 - val_time_distributed_2_loss: 1.0002 - val_time_distributed_3_loss: 0.9911 - val_time_distributed_4_loss: 1.0076 - val_time_distributed_5_loss: 0.9977 - val_time_distributed_6_loss: 1.0008 - val_time_distributed_7_loss: 1.0102 - val_time_distributed_8_loss: 1.0039\n",
      "Epoch 2/20000\n",
      "Epoch 2/20000\n",
      "3840/6400 [=================>............] - ETA: 48s - loss: 8.9252 - time_distributed_1_loss: 0.9988 - time_distributed_2_loss: 1.0002 - time_distributed_3_loss: 0.9744 - time_distributed_4_loss: 0.9993 - time_distributed_5_loss: 1.0040 - time_distributed_6_loss: 1.0011 - time_distributed_7_loss: 0.9938 - time_distributed_8_loss: 1.0028 "
     ]
    }
   ],
   "source": [
    "Path = 'try6'\n",
    "make_folder(Path)\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "    log_dir='./' + Path, histogram_freq=0, write_graph=True, write_images=True)\n",
    "filepath = './' + Path + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, verbose=0, save_best_only=False,\n",
    "                                             save_weights_only=False, mode='min', period=1)\n",
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 2 GPUs.\n",
    "# This assumes that your machine has 2 available GPUs.\n",
    "#parallel_model = multi_gpu_model(model, gpus=2)\n",
    "#parallel_model.compile(optimizer=Adam(3e-5),loss='mse')\n",
    "model.fit([amp_off,phase_off,freq_off,qf_off, amp_on, phase_on, freq_on, qf_on], \n",
    "          [amp_off,phase_off,freq_off,qf_off, amp_on, phase_on, freq_on, qf_on],\n",
    "          validation_data=([amp_off,phase_off,freq_off,qf_off, amp_on, phase_on, freq_on, qf_on], \n",
    "          [amp_off,phase_off,freq_off,qf_off, amp_on, phase_on, freq_on, qf_on]),\n",
    "          epochs=20000,batch_size=1280, callbacks=[tbCallBack, checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('./' + Path + '/end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dc_vec[0:128].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "e = Nd_mat[\"Amplitude [V]\"][:,:,:,1,2].reshape(-1,128)\n",
    "\n",
    "h5_sho_spec_inds = px.hdf_utils.getAuxData(h5_sho_fit, auxDataName='Spectroscopic_Indices')[0]\n",
    "h5_sho_spec_vals = px.hdf_utils.getAuxData(h5_sho_fit, auxDataName='Spectroscopic_Values')[0]\n",
    "\n",
    "voltage_reshape = h5_sho_spec_vals[1] + h5_sho_spec_vals[2]\n",
    "\n",
    "voltage_reshape.shape\n",
    "\n",
    "dc_vec=dc_vec[::124]\n",
    "plt.plot(dc_vec[0:128],amp_off[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h5_file = h5_main.file\n",
    "h5_spec_vals = h5_file[px.io.hdf_utils.get_attr(h5_main, 'Spectroscopic_Values')]\n",
    " \n",
    "dc_vec = np.squeeze(h5_spec_vals[h5_spec_vals.attrs['DC_Offset']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = Model(inputs=input_off_amp, outputs=out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "type(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 8 GPUs.\n",
    "# This assumes that your machine has 8 available GPUs.\n",
    "parallel_model = multi_gpu_model(model, gpus=8)\n",
    "parallel_model.compile(loss='categorical_crossentropy',\n",
    "                       optimizer='rmsprop')\n",
    "\n",
    "# This `fit` call will be distributed on 8 GPUs.\n",
    "# Since the batch size is 256, each GPU will process 32 samples.\n",
    "parallel_model.fit(x, y, epochs=20, batch_size=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
